{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5115f8-3a8f-4299-8a76-d0e05fa5b3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement splitfolders (from versions: none)\n",
      "ERROR: No matching distribution found for splitfolders\n"
     ]
    }
   ],
   "source": [
    "!pip install splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0eb1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "# import splitfolders \n",
    "# import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math \n",
    "import time \n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ae2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b043c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTKDataset(Dataset):\n",
    "    '''\n",
    "        Inputs:\n",
    "            dataFrame : Pandas dataFrame\n",
    "            transform : The transform to apply to the dataset\n",
    "    '''\n",
    "    def __init__(self, dataFrame, transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "        data_holder = dataFrame.pixels.apply(lambda x: np.array(x.split(\" \"),dtype=float))\n",
    "        arr = np.stack(data_holder)\n",
    "#         arr = arr / 255.0\n",
    "        arr = arr.astype('float32')\n",
    "        arr = arr.reshape(arr.shape[0], 48, 48, 1)\n",
    "        # reshape into 48x48x1\n",
    "        self.data = arr\n",
    "        \n",
    "        self.age_label = np.array(dataFrame.age[:])      \n",
    "        # self.gender_label = np.array(dataFrame.gender[:])\n",
    "#         self.eth_label = np.array(dataFrame.ethnicity[:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        data = self.transform(data)\n",
    "        \n",
    "        # labels = torch.tensor((self.age_label[index], self.gender_label[index]))\n",
    "        # labels = torch.tensor((self.gender_label[index]))\n",
    "        labels = torch.tensor((self.age_label[index]))\n",
    "   \n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02d05d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0a20b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: torch.Size([32, 1, 48, 48])\n",
      "Shape of lables: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataFrame = pd.read_csv(r\"C:\\Users\\shimi\\Desktop\\xuexi\\413\\final\\age_gender.gz\", compression='gzip')\n",
    "# Construct age bins\n",
    "# age_bins = [0,10,15,20,25,30,40,50,60,120]\n",
    "# age_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# dataFrame['bins'] = pd.cut(dataFrame.age, bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Split into training and testing\n",
    "train_dataFrame, validation_test_dataFrame = train_test_split(dataFrame, test_size=0.2)\n",
    "validation_dataFrame, test_dataFrame = train_test_split(validation_test_dataFrame, test_size=0.5)\n",
    "\n",
    "# get the number of unique classes for each group\n",
    "class_nums = {'age_num':len(dataFrame['age'].unique()), 'gen_num':len(dataFrame['gender'].unique())}\n",
    "\n",
    "# Define train and test transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49,), (0.23,))\n",
    "])\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49,), (0.23,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.49,), (0.23,))\n",
    "])\n",
    "\n",
    "# Construct the custom pytorch datasets\n",
    "train_set = UTKDataset(train_dataFrame, transform=train_transform)\n",
    "validation_set = UTKDataset(test_dataFrame, transform=validation_transform)\n",
    "test_set = UTKDataset(test_dataFrame, transform=test_transform)\n",
    "\n",
    "# Load the datasets into dataloaders\n",
    "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Sanity Check\n",
    "for data, lables in trainloader:\n",
    "    print(f'Shape of training data: {data.shape}')\n",
    "    print(f'Shape of lables: {lables.shape}')\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d5c6f75b-f855-4dcb-9a7f-70d0e514c75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>10000</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20170117104547721.jpg.chip.jpg</td>\n",
       "      <td>38 72 82 77 80 79 50 27 29 34 33 44 31 34 34 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>10001</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20170117104603706.jpg.chip.jpg</td>\n",
       "      <td>97 103 110 107 100 107 116 125 144 155 154 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>10002</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20170117104604974.jpg.chip.jpg</td>\n",
       "      <td>119 119 121 114 49 30 34 31 33 35 39 41 42 48 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>10003</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20170117104606138.jpg.chip.jpg</td>\n",
       "      <td>252 251 173 124 98 90 85 84 83 82 82 80 80 83 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>10004</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20170117104625949.jpg.chip.jpg</td>\n",
       "      <td>190 190 190 188 189 184 115 80 106 140 141 146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>10495</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170109134017138.jpg.chip.jpg</td>\n",
       "      <td>89 29 9 3 1 1 6 3 4 6 9 21 44 81 124 159 170 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>10496</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170116175630702.jpg.chip.jpg</td>\n",
       "      <td>233 241 243 247 243 237 237 240 241 239 230 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>10497</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170116211713681.jpg.chip.jpg</td>\n",
       "      <td>2 3 3 4 7 21 21 24 58 180 220 221 226 232 238 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>10498</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170117130627761.jpg.chip.jpg</td>\n",
       "      <td>22 25 30 34 51 81 89 95 98 105 113 117 118 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>10499</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20170117130626511.jpg.chip.jpg</td>\n",
       "      <td>117 59 56 71 97 64 62 118 135 156 182 204 213 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age  ethnicity  gender                        img_name  \\\n",
       "10000       10000   29          1       0  20170117104547721.jpg.chip.jpg   \n",
       "10001       10001   29          1       0  20170117104603706.jpg.chip.jpg   \n",
       "10002       10002   29          1       0  20170117104604974.jpg.chip.jpg   \n",
       "10003       10003   29          1       0  20170117104606138.jpg.chip.jpg   \n",
       "10004       10004   29          1       0  20170117104625949.jpg.chip.jpg   \n",
       "...           ...  ...        ...     ...                             ...   \n",
       "10495       10495   29          0       1  20170109134017138.jpg.chip.jpg   \n",
       "10496       10496   29          0       1  20170116175630702.jpg.chip.jpg   \n",
       "10497       10497   29          0       1  20170116211713681.jpg.chip.jpg   \n",
       "10498       10498   29          0       1  20170117130627761.jpg.chip.jpg   \n",
       "10499       10499   29          0       1  20170117130626511.jpg.chip.jpg   \n",
       "\n",
       "                                                  pixels  \n",
       "10000  38 72 82 77 80 79 50 27 29 34 33 44 31 34 34 1...  \n",
       "10001  97 103 110 107 100 107 116 125 144 155 154 176...  \n",
       "10002  119 119 121 114 49 30 34 31 33 35 39 41 42 48 ...  \n",
       "10003  252 251 173 124 98 90 85 84 83 82 82 80 80 83 ...  \n",
       "10004  190 190 190 188 189 184 115 80 106 140 141 146...  \n",
       "...                                                  ...  \n",
       "10495  89 29 9 3 1 1 6 3 4 6 9 21 44 81 124 159 170 1...  \n",
       "10496  233 241 243 247 243 237 237 240 241 239 230 21...  \n",
       "10497  2 3 3 4 7 21 21 24 58 180 220 221 226 232 238 ...  \n",
       "10498  22 25 30 34 51 81 89 95 98 105 113 117 118 123...  \n",
       "10499  117 59 56 71 97 64 62 118 135 156 182 204 213 ...  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[10000:10500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BASICCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BASICCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.drop1=nn.Dropout(0.2)\n",
    "        self.drop2=nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = x.view(-1, 256 * 6 * 6)            \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = F.relu(self.fc3(x)) \n",
    "        x = F.relu(self.fc4(x)) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BASICCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.6)\n",
    "\n",
    "n_total_steps = len(trainloader)\n",
    "\n",
    "lowest_loss = []\n",
    "# accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    lowest_in_epoch = math.inf\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.float()\n",
    "        print(labels)\n",
    "        # Forward pass\n",
    "        outputs = model(images).flatten()\n",
    "        print(outputs)\n",
    "        # print(f'Shape of training data: {outputs.shape}')\n",
    "        # print(f'Shape of lables: {labels.shape}')\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "        # _, pred = torch.max(outputs.data, 1)\n",
    "        # total += labels.size(0)\n",
    "        # correct += (pred == labels).sum()\n",
    "\n",
    "        if loss.item() < lowest_in_epoch:\n",
    "            lowest_in_epoch = loss.item()\n",
    "    lowest_loss.append((epoch, lowest_in_epoch))\n",
    "    # accuracy = 100 * correct / total\n",
    "    # accuracy_list.append((epoch, accuracy.item()))\n",
    "    scheduler.step()\n",
    "print(lowest_loss)\n",
    "# print(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48fb4e-5adc-42d4-b097-8592cf718b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_list)\n",
    "print(lowest_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238ac5d-6951-4ca4-83fb-82fcb397734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Iterate through test dataset\n",
    "for images, labels in testloader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (pred == labels).sum()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d131c81-2b4a-4616-b4f7-86c1797b283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for i in range(num_epochs):\n",
    "    x_list.append(i)\n",
    "    y_list.append(lowest_loss[i][1])\n",
    "plt.plot(x_list, y_list)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Lowest Loss\")\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
